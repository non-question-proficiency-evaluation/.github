# NEXS-399: [R&D] non question proficiency evaluation

**Type:** Story  
**Status:** In Progress  
**Priority:** High  
**Story Points:** 5.0  
**Parent:** NEXS-210  
**Epic Link:** Drive recommendations through LOs or Section headings  
**Sprint:** XLP NEXUS AI 9, XLP NEXUS AI 6, XLP NEXUS AI 7

**JIRA Link:** [https://pearson.atlassian.net/browse/NEXS-399](https://pearson.atlassian.net/browse/NEXS-399)

---

## Description

Quantify how much a student's proficiency level should increase after engaging with different learning materials (e.g., watching a video, reading a PDF). The goal is to define measurable heuristics or model-driven approaches to estimate proficiency gain based on content type, duration, and complexity.

---

## Details

| Field | Value |
|-------|-------|
| **Project** | Nexus AI (NEXS) |
| **Assignee** | Mostafa Rezaee |
| **Reporter** | Nikolay Gaykov |
| **Created** | Wed, 15 Oct 2025 10:48:05 -0400 |
| **Updated** | Thu, 20 Nov 2025 09:21:15 -0500 |
| **First Response** | Tue, 4 Nov 2025 15:45:52 +0000 |
| **Rank** | 2\|i1wyrd: |
| **Relevance** | 1 |
| **Tendency** | 1 |
| **Severity** | 3 - Medium - minor functionality broken |
| **PB Ranking** | 6. Not Ranked |
| **Type of Work** | Maintenance |
| **Project Number** | 068-688 (2.0 Maint) |
| **Oracle Entity** | 9516:Pearson Education Inc |
| **Azure AD Tenant** | pearson.com |

---

## Acceptance Criteria

- Define a framework or formula to estimate proficiency improvement per content type (video, text/PDF, etc).
- Include factors such as duration, difficulty (e.g., completion rate, time spent). Research on other metrics?
- Document how initial vs. final proficiency is calculated or inferred.
- Provide example mappings
- Present a short summary or prototype report showing expected proficiency change given different learning inputs.

---

## Comments

### [2025-11-04] - Unknown Author

Pending: talk to A+ team regarding how to give points to people who watch videos.

### [2025-11-06] - Mostafa Rezaee

I just started working on **NEXS-399 [R&D] non-question proficiency evaluation**.

My plan for this task is:

1. Review public research and metrics on learning effectiveness and engagement (video, text, interactive content).
2. Identify key factors affecting proficiency gain (content type, duration, difficulty, interaction level).
3. Propose a heuristic or model-based formula to estimate proficiency improvement per content type.
4. Provide example mappings or a short prototype report showing expected gains under different scenarios.

---

## Additional Information

- **DoR:** None
- **Demo Ready 2:** No
- **Target for demo:** No
- **Bounce Required:** No
- **Impact to 044/376:** No
- **Known Issues for Support Team:** No
- **Will there be any performance impact observed during this deployment:** No
- **Deployment time > 30 mins in lower environment:** No
- **Datafix - Updates to EBS/IPM/MDM Schema:** EBS
- **Migration Sequence:** Migrate as per the sequence in KP
- **Job hold list:** N/A
- **Oracle Analysis:** 0000:Default
- **Oracle Future:** 0000:Default
- **Oracle Internal:** 0000:Default

---

## Contacts

- Project contact:  
- Downtime window contact:

---

## Customer Impact

Will the product/service incur downtime or degradation of functionality during this change? If so, for how long?  
What will customers, users and/or support teams experience during this change window?  
During what period of the change will customers see this impact?  
Will there be any impact to any other products, integrations, systems, or services?

---

## Customer Impact Statement

The customer impact statement should be written from a customer perspective. (What will the customer not be able to see and/or do during the change window?) Please include details of all applications and functionality within those applications (including integrations) expected to be impacted during the release.
